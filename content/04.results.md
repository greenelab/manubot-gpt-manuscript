# Results

We used this infrastructure to revise an existing manuscript as well as to author a new one.
We back-ported the changes in Manubot to a manuscript describing the Clustermatch Correlation Coefficient (CCC) [@doi:10.1101/2022.06.15.496326].
The CCC was designed to capture both linear and non-linear relationships between variables.
The CCC manuscript describes its use, in particular with gene expression data.

The abstract of the CCC manuscript before revision had a Flesh-Kincaid readability score of X and a grade level of Y.
> PREVIOUS_VERSION

After suggested revisions, the readability score was X and the grade level was Y and read as follows:
> NEW_VERSION

The full manuscript before AI-based revision is available at [link], and the revised version is available at [new_link].
We noticed that the model has difficulty with the Manubot citation style, which may lead to some references becoming incorrect.
This pipeline is not fully automated: authors will need to review changes and verify the output.

We also used this framework in the context of authoring a new manuscript that described a publishing infrastructure that implemented large language models to suggest revisions.
The abstract before revisions had a Flesh-Kincaid readability score of X and a grade level of Y and read as follows:
> Academics often communicate through scholarly manuscripts.
> These manuscripts describe new advances, summarize existing literature, or argue for changes in the status quo.
> Writing and revising manuscripts can be a time-consuming process.
> Large language models are bringing new capabilities to many areas of knowledge work.
> We integrated the use of large language models into the Manubot publishing ecosystem.
> Users of Manubot can run a workflow, which will trigger a series of queries to OpenAI's language models, produce revisions, and create a timestamped set of suggested revisions.
> Given the amount of time that researchers put into crafting prose, we expect this advance to radically transform the type of knowledge work that academics perform.

After suggested revisions, abstract had a Flesh-Kincaid readability score of X and a grade level of Y and read as follows:
> NEW_VERSION
