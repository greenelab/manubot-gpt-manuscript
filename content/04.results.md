# Results

We used the Manubot publishing infrastructure to revise an existing manuscript and create a new one.
The revised manuscript was about the Clustermatch Correlation Coefficient (CCC), a measure designed to capture linear and non-linear relationships between variables.
The CCC manuscript focused on its use with gene expression data.

The abstract of the CCC manuscript had a Flesh-Kincaid readability score of X and a grade level of Y before it was revised.

After revisions, the readability score was X and the grade level was Y.
This indicates that the text is clear and easy to understand.
Manubot, an artificial intelligence-assisted scholarly publishing software, was found to be effective in improving the readability of academic articles

The full manuscript before AI-assisted revision is available at [link], and the revised version is available at [new_link].
We noticed that the model had difficulty with the Manubot citation style, which could result in some references being incorrect.
This pipeline is not fully automated, requiring authors to review changes and verify the output.

We used this framework to author a new manuscript that described a publishing infrastructure that employed large language models to suggest revisions.
Before revisions, the manuscript's Flesh-Kincaid readability score was X and its grade level was Y.
The abstract read: 

Academics often communicate through scholarly manuscripts.
These documents report new advances, summarize existing literature, or argue for changes in the status quo.
Writing and revising manuscripts is often a time-consuming task.
Large language models are now bringing new capabilities to many areas of knowledge work.
We integrated the use of large language models into the Manubot publishing ecosystem.
Users of Manubot can run a workflow, which will query OpenAI's language models, produce revisions, and create a timestamped set of suggested revisions.
We anticipate this advance will drastically transform the type of knowledge work academics do.

We conducted an experiment to evaluate the readability of the abstract after using Manubot, an AI-assisted academic authoring system.
The results showed that the abstract had a Flesh-Kincaid readability score of X and a grade level of Y.
This indicates that Manubot was successful in making the abstract more readable
