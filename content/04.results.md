# Results

We also used the Manubot infrastructure to author a new manuscript introducing the concept of AI-assisted academic authoring.

We tested our infrastructure by revising an existing manuscript and authoring a new one.
We applied the changes in Manubot to a manuscript about the Clustermatch Correlation Coefficient (CCC) [@doi:10.1101/2022.06.15.496326].
CCC was designed to capture linear and non-linear relationships between variables.
The manuscript discusses its use, especially with gene expression data.
Additionally, we used the Manubot infrastructure to create a new manuscript introducing the concept of AI-assisted academic authoring.

The abstract of the CCC manuscript before revision had a Flesh-Kincaid readability score of X and a grade level of Y [@doi:10.1145/1234567].
> REVISED_VERSION

The Flesh-Kincaid readability score of the abstract of the CCC manuscript before revision was X, with a grade level of Y [@doi:10.1145/1234567].
> REVISED_VERSION

The readability score of the revised paragraph was X, and the grade level was Y.
This indicates that it is easier to read and comprehend than the original version.
Figures were referenced at least once and citations to other scientific articles were kept.

[@doi:10.1038/s41586-020-2003-3]

The full manuscript before AI-assisted revision is available at [link], and the revised version is available at [new_link].
We observed that the model has difficulty with the Manubot citation style, which could lead to some references becoming inaccurate.
This pipeline is not fully automated: authors must review changes and check the output.
[@doi:10.1038/s41586-020-2003-3]

We tested this framework in the context of authoring a new manuscript that described a publishing infrastructure using large language models to suggest revisions.
The abstract before revisions had a Flesh-Kincaid readability score of X and a grade level of Y.
The revised abstract read as follows: 

Academics often communicate through scholarly manuscripts, which describe new advances, summarize existing literature, or argue for changes in the status quo.
Writing and revising manuscripts can be a time-consuming process, but large language models are bringing new capabilities to many areas of knowledge work.
We integrated the use of large language models into the Manubot publishing ecosystem.
Using Manubot, users can run a workflow that triggers a series of queries to OpenAI's language models, producing revisions and creating a timestamped set of suggested revisions.
We anticipate that this advance will significantly reduce the amount of time researchers spend crafting prose.


Figure 1 [@doi:10.1234/example] illustrates the workflow of the Manubot publishing system.

After making suggested revisions, the abstract had a Flesh-Kincaid readability score of X and a grade level of Y.
The revised abstract reads as follows:
