## Implementing AI-based revision into the Manubot publishing ecosystem

We propose a human-centric approach for the use of AI in manuscript writing, which consists of the following steps:
1) human authors write the manuscript content;
2) an LLM revises the manuscript, generating a set of suggested changes;
3) human authors review the suggested changes, and the approved edits are then integrated into the manuscript.
By focusing on human review, this approach attempts to mitigate the risk of generating incorrect or misleading information.
To implement this human-centric approach, we developed a tool called the Manubot AI Editor, which is part of the Manubot infrastructure for scholarly publishing [@doi:10.1371/journal.pcbi.1007128].


### Overview of the Manubot AI Editor

![
**AI-based revision applied on a Manubot-based manuscript.**
**a)** A manuscript (written with Manubot) with different sections.
**b)** The prompt generator integrates metadata using prompt templates to generate section-specific prompts for each paragraph.
If a paragraph belongs to a non-standard section, then a default prompt will be used to perform a basic revision only.
The prompt for the Methods section includes the formatting of equations with identifiers.
All sections' prompts include these instructions: *"the text grammar is correct, spelling errors are fixed, and the text has a clear sentence structure"*, although these are only shown for abstracts.
Our tool allows the user to provide a custom prompt instead of using the default ones shown here.
](images/figure_1.svg "AI-based revision applied on a Manubot manuscript"){#fig:ai_revision width="75%"}

The Manubot AI Editor is an AI-based revision infrastructure integrated into Manubot [@doi:10.1371/journal.pcbi.1007128], a tool for collaborative writing of scientific manuscripts.
Manubot integrates with popular version control platforms such as GitHub, allowing authors to easily track changes and collaborate on writing in real time.
Furthermore, Manubot automates the process of generating a formatted manuscript (e.g., HTML, PDF, DOCX; Figure {@fig:ai_revision}a shows the HTML output).
Built upon this modern and open paradigm, our Manubot AI Editor ([https://github.com/manubot/manubot-ai-editor](https://github.com/manubot/manubot-ai-editor)) includes three components:
1) a Python library that provides classes and functions to read the manuscript content and its metadata, calls the LLM for automatic text revision, and writes the results back;
2) a GitHub Actions workflow that uses our Python library within GitHub to preserve provenance information for transparency;
3) a prompt generator that integrates the manuscript's metadata using prompt templates to generate section-specific prompts for each paragraph (Figure {@fig:ai_revision}b).


The GitHub Actions workflow enables users to easily trigger an automated revision task on either the entire manuscript or specific sections of it.
When the action is triggered, the manuscript is parsed by section and then by paragraph (Figure {@fig:ai_revision}b), which are then passed to the language model along with a set of custom prompts.
The model subsequently returns a revised version of the text.
Our workflow leverages the GitHub API to generate a new pull request, allowing the user to review and modify the output before merging the changes into the manuscript.
This workflow assigns text attribution to either the human user or the AI language model, which may be important in light of potential future legal decisions that could reshape the copyright landscape concerning the outputs of generative models.


We used the [OpenAI API](https://openai.com/api/) for access to these models.
Since this API incurs a cost with each run that depends on the manuscript length, we implemented a workflow in GitHub Actions that can be manually triggered by the user.
Our implementation allows users to tune the costs to their needs by enabling them to select specific sections for revision instead of the entire manuscript.
Additionally, several model parameters can be adjusted to further tune costs, such as the language model version (including the current GPT-3.5 Turbo and GPT-4, and potentially newly published ones), how much risk the model will take, or the "quality" of the completions.
For instance, using Davinci models, the cost per run is under $0.50 for most manuscripts.
More details about the implementation, installation, and usage of the Manubot AI Editor can be found in the [Supplementary Material](#sec:supp_mat).
