# Methods

We implemented the AI-based revision infrastructure in Manubot [@doi:10.1371/journal.pcbi.1007128].
Manubot takes Markdown as input and produces HTML, PDF, or other pandoc-supported formats as output.
It includes a robust cite-by-persistent-identifier infrastructure.
Its workflows are implemented in continuous integration software (Appveyor, GitHub Actions, etc).
Most workflows run with each commit.

We used the OpenAI API for access to large language models, with a focus on the completion endpoints.
This API incurs a cost with each run that depends on manuscript length.
Because of this cost, we implemented our workflow in GitHub actions, making it triggerable by the user.
The user can select the model that they wish to use, allowing costs to be tuned.
With the most complex model, `text-davinci-003`, the cost per run is under $0.50 for many manuscripts.

When the user triggers the action, the manuscript is parsed by section and then by paragraph, passed to the model along with a set of custom prompts, returned, reformatted, and output.
Our workflow then uses the GitHub API to generate a new pull request, allowing the user to review and, if desired, modify the output before merging.
This workflow allows text to be attributed either to the initial user or to the language model, which may be important in the event that future legal decisions alter the copyright landscape around the outputs of generative models.