# Conclusions

We implemented AI-based revision models into the publishing infrastructure provided by Manubot.
While humans have written most manuscripts, the process is time-consuming, and academic writing can be challenging to read.
We sought to incorporate technology into an existing publishing platform to assist researchers in the task of communicating their findings to the community.
We implemented a workflow that authors can trigger to suggest revisions.
It uses GPT-3 models through the OpenAI API and generates a pull request of revisions that authors can review.
We provide default parameters for GPT-3 models that work well for our use cases across different sections and manuscripts.
Users can customize the revision by selecting only specific sections or adjusting the model's behavior to fit their needs and budget.
Although evaluating a revision tool is subjective, we found that many paragraphs were improved.
Parts of the text that were difficult for the AI model to revise highlighted paragraphs that also could stymie human readers.


We designed section-specific prompts to guide the GPT-3-based revision of the text.
We were surprised that, in one Methods section, the model revised a human-overlooked error in referencing a symbol from an equation.
Opportunities exist to improve the underlying AI-based revisions, such as further refining prompts using few-shot learning [@doi:10.1145/3386252] or fine-tuning the model with an additional corpus of academic writing focused on particularly challenging sections.
Fine-tuning using preprint-publication pairs [@doi:10.1371/journal.pbio.3001470] may provide a strategy to detect sections or phrases likely to be changed during peer review.
Our approach used GPT-3, which lacks a contextual thread between queries.
Using chatbots that retain context, such as OpenAI's ChatGPT [@url:https://openai.com/blog/chatgpt], could enable the revision of individual paragraphs while considering previously processed text.
Once an official API becomes available for ChatGPT, we plan to update our workflow to support this strategy.
There are many potential models, including the BLOOM [@arxiv:2211.05100], GLM [@arxiv:2210.02414], or Meta's OPT [@arxiv:2205.01068] ones, which are open though lacking the highly usable OpenAI API.
Even with these limitations, we found models captured the main ideas and generated a revision that often communicated the intended meaning more clearly and concisely.
It is important to note, however, that our assessment of performance in case studies was necessarily subjective, as there could be, for example, writing styles that might not be widely shared across researchers.


Using these types of tools for scientific authoring is controversial.
Several questions arise concerning the novelty or ownership of the text generated by these models.
The program chairs of the upcoming International Conference on Machine Learning (ICML) prohibit *"papers that include text generated from a large-scale language model (LLM)"* [@url:https://icml.cc/Conferences/2023/llm-policy], while editing tools such as for grammar and spelling correction are allowed.
We focus on revising an *existing* text written by a human author.
In this way, it is not different from other automatic tools such as Grammarly [@url:https://www.grammarly.com/].
While there are concerns, there is also significant opportunity.
Our work lays the foundation for a future where academic manuscripts are constructed by both human and machine contributions.
Academic writing follows a certain style.
The writing process is a time-consuming task that requires a significant amount of effort in thinking *how* to communicate a result or finding that was already obtained.
The increasing ability of machines to improve a scholarly text means that humans can focus on *what* to communicate to other peers.
A future in which scientists are not limited by their ability to communicate in a very specific style but instead only by their ideas and ability to perform experiments that reveal underlying organizing principles of ourselves and our environment could be a more equitable and productive future for research.
