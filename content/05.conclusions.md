## Conclusions

We implemented AI-based revision models into the Manubot publishing platform to help researchers communicate their findings to the community.
Writing academic papers can be time-consuming and challenging to read, so we sought to use technology to make the process easier.
Our AI-based revision workflow uses a prompt generator to create manuscript- and section-specific instructions for the language model.
Authors can easily trigger this workflow from the GitHub repository, which then suggests revisions that can be reviewed by the author.
This workflow uses GPT-3 models through the OpenAI API to generate a pull request of revisions.
We set default parameters for GPT-3 models that work well for our use cases across different sections and manuscripts, but users can also customize the revision by selecting specific sections or adjusting the model's behavior to fit their needs and budget.
Although the evaluation of the revision tool is subjective, we found that most paragraphs were improved.
The AI model also highlighted certain paragraphs that were difficult to revise, which could be challenging for human readers too.


We designed section-specific prompts to guide the revision of text using GPT-3.
Surprisingly, in one Methods section, the model detected an error when referencing a symbol in an equation that had been overlooked by humans.
However, abstracts were more challenging for the model to revise, often removing background information about the research problem.
There are opportunities to improve the AI-based revisions, such as further refining prompts using few-shot learning [@doi:10.1145/3386252] or fine-tuning the model using an additional corpus of academic writing focused on particularly challenging sections.
Fine-tuning using preprint-publication pairs [@doi:10.1371/journal.pbio.3001470] may help to identify sections or phrases likely to be changed during peer review.
Our approach used GPT-3 to process each paragraph of the text, but it lacked a contextual thread between queries, which mainly affected the Results and Methods sections.
To address this, we plan to use chatbots that retain context, such as OpenAI's ChatGPT, to enable the revision of individual paragraphs while considering previously processed text.
Since an official ChatGPT API became available recently, we can update our workflow to support this strategy.
Other open models, such as BLOOM [@arxiv:2211.05100], GLM [@arxiv:2210.02414], or OPT [@arxiv:2205.01068], provide similar capabilities but lack the user-friendly OpenAI API.
Despite these limitations, we found that the models captured the main ideas and generated a revision that often communicated the intended meaning more clearly and concisely.
It is important to note, however, that our assessment of performance in the case studies was necessarily subjective, as there could be writing styles that are not widely shared across researchers.


The use of AI-assisted tools for scientific authoring is controversial [@doi:10.1038/d41586-023-00056-7; @doi:10.1038/d41586-023-00107-z].
There are questions about the originality and ownership of texts created by these models.
For example, *Nature* journal has stated that any use of these models must be documented [@doi:10.1038/d41586-023-00191-1], and the International Conference on Machine Learning (ICML) has prohibited the submission of *"papers that include text generated from a large-scale language model (LLM)"* [@url:https://icml.cc/Conferences/2023/llm-policy], although tools for grammar and spelling correction are allowed.
Our work focuses on improving existing text written by a human author, similar to other tools like [Grammarly](https://www.grammarly.com).
All changes made by humans and AI are tracked in a version control system, which allows for transparency.
Despite the concerns, there are also opportunities.
Our work lays the foundation for a future in which humans and machines collaborate to create academic manuscripts.
Scientific articles must follow a certain style, which can be time-consuming and require a lot of effort to think about *how* to communicate a result or finding that has already been obtained.
As machines become more capable of enhancing scholarly text, humans can focus more on *what* to communicate to others, rather than on *how* to write it.
This could lead to a more equitable and productive future for research, where scientists are limited only by their ideas and ability to conduct experiments to uncover the underlying organizing principles of ourselves and our environment.
