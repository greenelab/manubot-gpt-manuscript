## Conclusions

Our tool, the Manubot AI Editor, integrates AI-based revision models into the Manubot publishing platform.
Writing academic papers can be time-consuming and challenging to comprehend, so we aimed to use technology to assist researchers in communicating their findings effectively.
Our AI-based revision workflow employs a prompt generator that creates manuscript- and section-specific instructions for the language model.
Authors can easily initiate this workflow from the GitHub repository to suggest revisions that can be reviewed later.
This workflow utilizes GPT-3 models via the OpenAI API, generating a pull request of revisions for authors to review.
We have established default parameters for GPT-3 models that perform well across different sections and manuscripts.
Users also have the option to customize the revision process by selecting specific sections, adjusting the model's behavior to suit their needs and budget, and even providing custom prompts instead of using the default, section-specific ones.
This can be particularly beneficial for specific use cases that do not necessitate a complex revision.
Although evaluating automatic text revision is challenging, we found that most paragraphs were enhanced, while in some instances the model removed crucial information or introduced errors.
The AI model also identified certain paragraphs that were difficult to revise, which could pose challenges for human readers as well.


We designed section-specific prompts to guide the revision of text using GPT-3.
Surprisingly, in one Methods section, the model detected an error when referencing a symbol in an equation that had been overlooked by humans.
However, revising abstracts proved more challenging for the model, as revisions often removed background information about the research problem.
There are opportunities to improve the AI-based revisions, such as further refining prompts using few-shot learning [@doi:10.1145/3386252], or fine-tuning the model using an additional corpus of academic writing focused on particularly challenging sections.
Fine-tuning using preprint-publication pairs [@doi:10.1371/journal.pbio.3001470] may help to identify sections or phrases likely to be changed during peer review.
Our approach used GPT-3 to process each paragraph of the text, but it lacked a contextual thread between queries, which mainly affected the Results and Methods sections.
Using chatbots that retain context, such as [OpenAI's ChatGPT](https://openai.com/blog/chatgpt), could enable the revision of individual paragraphs while considering previously processed text.
We plan to update our workflow to support this strategy.
Open and semi-open models, such as BLOOM [@arxiv:2211.05100], Meta's Llama 2 [@arxiv:2307.09288], and Mistral 7B [@arxiv:2310.06825], are growing in popularity and capabilities, but they lack the user-friendly OpenAI API.
We used a combination of human evaluation and automated tools available at the time to assess the outcomes of the AI-based revisions.
Recent frameworks such as [OpenAI Evals](https://github.com/openai/evals) or strategies such as LLM-as-a-Judge [@arxiv:2306.05685] could be used to evaluate the quality of the revisions in a more automated way.
Despite these limitations, we found that models captured the main ideas and generated a revision that often communicated the intended meaning more clearly and concisely.
While our study used OpenAI's GPT-3, the Manubot AI Editor supports both GPT 3.5 Turbo and GPT-4 models, which were made available after the completion of our research.


The use of AI-assisted tools for scientific authoring is controversial [@doi:10.1038/d41586-023-00056-7; @doi:10.1038/d41586-023-00107-z].
Questions arise concerning the originality and ownership of texts generated by these models.
For example, the *Nature* journal has established that any use of these models in scientific writing must be documented [@doi:10.1038/d41586-023-00191-1], and the International Conference on Machine Learning (ICML) has prohibited the submission of "papers that include text generated from a large-scale language model (LLM)" [@url:https://icml.cc/Conferences/2023/llm-policy], although editing tools for grammar and spelling correction are allowed.
Our work, however, focuses on revising *existing* text written by a human author.
Additionally, all changes made by humans and AI are tracked in the version control system, which allows for full transparency.
Despite the concerns, there are also significant opportunities.
Our work lays the foundation for a future in which humans and machines construct academic manuscripts together.
Scientific articles need to adhere to a certain style, which can make the writing time-consuming and require a significant amount of effort to think about *how* to communicate a result or finding that has already been obtained.
As machines become increasingly capable of improving scholarly text, humans can focus more on *what* to communicate to others, rather than on *how* to write it.
This could lead to a more equitable and productive future for research, where scientists are only limited by their ideas and ability to conduct experiments to uncover the underlying organizing principles of ourselves and our environment.
