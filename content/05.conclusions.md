## Conclusions

Our tool, the Manubot AI Editor, integrates AI-based revision models into the Manubot publishing platform.
Writing academic papers can be time-consuming and challenging to comprehend, so we aimed to use technology to assist researchers in communicating their findings more effectively.
Our AI-based revision workflow uses a prompt generator that creates manuscript- and section-specific instructions for the language model.
Authors can easily trigger this workflow from the GitHub repository to suggest revisions that can be reviewed later.
This workflow utilizes OpenAI models, generating a pull request of revisions for authors to review.
We have established default parameters for these models that perform well for our use cases across different sections and manuscripts.
Users also have the option to customize the revision process by selecting specific sections, adjusting the model's behavior to suit their needs and budget, and even providing custom prompts instead of using the default, section-specific ones.
This can be particularly beneficial for specific use cases that do not require a complex revision.
Although evaluating automatic text revision is challenging, we conducted both human and automated evaluations of the revisions generated by the AI model.
We found that most paragraphs were enhanced, while in some cases the model removed important information or introduced errors.
The AI model also highlighted certain paragraphs that were difficult to revise, which could pose challenges for human readers as well.


Our approach has some limitations.
We found that revising abstracts proved more challenging for the model, as revisions often removed background information about the research problem.
There are opportunities to improve the AI-based revisions, such as further refining prompts using few-shot learning [@doi:10.1145/3386252], or fine-tuning the model using an additional corpus of academic writing focused on particularly challenging sections.
Fine-tuning using preprint-publication pairs [@doi:10.1371/journal.pbio.3001470] may help to identify sections or phrases likely to be changed during peer review.
Our approach processed each paragraph of the text but lacked a contextual thread between queries, which mainly affected the Results and Methods sections.
Using chatbots that retain context could enable the revision of individual paragraphs while considering previously processed text.
We plan to update our workflow to support this strategy.
Regarding the LLM used, open and semi-open models, such as BLOOM [@arxiv:2211.05100], Meta's Llama 2 [@arxiv:2307.09288], and Mistral 7B [@arxiv:2310.06825], are growing in popularity and capabilities, but they lack the user-friendly OpenAI API.
We used the LLM-as-a-Judge method to automatically assess the quality of revisions, which has limitations such as the self-enhancement bias where LLMs tend to favor text generated by them.
Although our approach is based on revising human-generated text (and not generating answers from scratch), we used two LLM judges to address this potential issue: GPT 3.5 and GPT 4, which showed limited self-enhancement bias and high alignment with human preferences [@arxiv:2306.05685], and we found in this study that the automated assessments were consistent with our human evaluations.
Despite these limitations, we found that models captured the main ideas and generated a revision that often communicated the intended meaning more clearly and concisely.
While our study focused on OpenAI's GPT-3 and GPT-3.5 Turbo for revisions, the Manubot AI Editor is prepared to support future models.


The use of AI-assisted tools for scientific authoring is controversial [@doi:10.1038/d41586-023-00056-7; @doi:10.1038/d41586-023-00107-z].
Questions arise concerning the originality and ownership of texts generated by these models.
For example, the *Nature* journal has established that any use of these models in scientific writing must be documented [@doi:10.1038/d41586-023-00191-1], and the International Conference on Machine Learning (ICML) has prohibited the submission of *"papers that include text generated from a large-scale language model (LLM)"* [@url:https://icml.cc/Conferences/2023/llm-policy], although editing tools for grammar and spelling correction are allowed.
Our work, however, focuses on revising *existing* text written by a human author.
Additionally, all changes made by humans and AI are tracked in the version control system, which allows for full transparency.
Despite the concerns, there are also significant opportunities.
Our work lays the foundation for a future in which humans and machines construct academic manuscripts together.
Scientific articles need to adhere to a certain style, which can make the writing time-consuming and require a significant amount of effort to think about *how* to communicate a result or finding that has already been obtained.
As machines become increasingly capable of improving scholarly text, humans can focus more on *what* to communicate to others, rather than on *how* to write it.
This could lead to a more equitable and productive future for research, where scientists are only limited by their ideas and ability to conduct experiments to uncover the underlying organizing principles of ourselves and our environment.
