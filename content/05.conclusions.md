# Conclusions

We implemented AI-based models into publishing infrastructure.
While most manuscripts have been written by humans, the process is time consuming and academic writing can be difficult to parse.
We sought to develop a technology that academics could use to make their writing more understandable without changing the fundamental meaning.
This work lays the foundation for a future where academic manuscripts are constructed by a process that incorporates both human and machine authors.


<!-- I'm moving this from Methods, but it belongs here: -->
We found that, in general, the tool generated reasonable suggestions for most sections of the manuscripts, with paragraph that were greatly improved and others that needed minimal human review.
We also found, though, that for some paragraph the revision was not good enough, and in some cases it even made the text worse.
`EDIT LATER: `{.red} This was particularly true for the Methods sections, especially when more complex mathematical expressions were present.
Another section that did not yield the results we expected is the Abstracts, where and the Methods and Results sections, where the lack of more context made the tool less effective in the review of some paragraphs.

abstracts:
    - remember that the models are stochastic.
    - for the phenoplier abstract, the revision was not really great.
    - the user of the tool, in these cases, might want to run it again to obtain another revision.
    - for abstract, maybe we need to improve the prompts to keep more background information while keeping sentences shorter.


introductions:
    - really good for both
    - in phenoplier, the models did not keep the format of citations for one paragraph, although this can be easily fixed by a human.
        - the other paragraph that did not converge was a large one; this could be an indication that is not easy to understand and it should be split into smaller paragraphs.
        - therefore, the fact that the tool cannot process a paragraph of text can also provide insight about the quality of the writing.


- methods:
    - the model not only improved the text, but also fixed references to wrong mathematical symbols.


Mention AnthropicAI's Claude model (a competitor of ChatGPT): https://twitter.com/goodside/status/1611556749726605312
    - mention this when talking about chatbots based on GPT-3, but that keep context
    - this is a way to keep the paragraph-by-paragraph model, but with a chatbot interface to keep context and be independent of the context length of the model.


edits vs completion endpoints:
 - they are based on the same models, so maybe we only have to wait for the edits endpoint to be improved, since it provides the most natural interface for the revision of manuscripts


SUMMARY BETWEEN MODELS:
- The edits endpoint, however, provides the most natural interface for the revision of manuscripts, and since it's based on the Davinci models, we believe that it might become the best option for this task in the future.
- Curie models were not very good, but this could also be explained by the complexity of our prompts; maybe simplier prompts would work better.

- WE SHOW that the Davinci models are capable of revising a complex manuscript, and that any potential issue could be more related to the complexity of the prompts than to the models themselves.

- the models offers a wide variety of parameters to tune, for instance, "logit_bias" could be helpful to improve completion in the methods section (equations), which allows to provide a bias for specific tokens
- other models in the future will certainly improve the AI-assisted revision of scientific manuscripts


- read the "best practices" part, which has suggestions to improve, like using "best_of":
https://beta.openai.com/docs/guides/completion/inserting-text
- another improvement: check "finish_reason" to make sure it is "stop" and not "lenght" (which means max_tokens was too small)

- although Manubot manuscript are written in Markdown format, our prompts are independent of this markup language, and should work with other tools like Latex.

- another alternative is fine-tuning of models: https://beta.openai.com/docs/guides/fine-tuning
    - maybe using biorxiv or another corpus to train on specific sections of papers




SOMETHING ABOUT THE STOCHASTIC NATURE OF THE MODELS:, it would be nice to say that the stochastic nature of the models mimic a human author, and that this is a good thing, since it paradoxically makes the revision more natural and less robotic.
- humans do not revise a text always in the same way
