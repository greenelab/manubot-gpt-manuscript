## Conclusions

We implemented AI-based revision models into the Manubot publishing platform.
Writing academic papers can be time-consuming and challenging to read, so we sought to use technology to help researchers communicate their findings to the community.
We created a workflow that authors can trigger to suggest revisions.
This workflow uses GPT-3 models through the OpenAI API, generating a pull request of revisions that authors can review.
We set default parameters for GPT-3 models that work well for our use cases across different sections and manuscripts.
Users can also customize the revision by selecting specific sections or adjusting the model's behavior to fit their needs and budget.
Although the evaluation of the revision tool is subjective, we found that many paragraphs were improved.
The AI model also highlighted certain paragraphs that were difficult to revise, which could be challenging for human readers too.


We designed section-specific prompts to guide the revision of text using GPT-3.
Surprisingly, in one Methods section, the model detected an error that had been overlooked by humans.
However, abstracts were more challenging for the model to revise.
There are opportunities to improve the AI-based revisions, such as further refining prompts using few-shot learning or fine-tuning the model using an additional corpus of academic writing focused on particularly challenging sections.
Fine-tuning using preprint-publication pairs may help to identify sections or phrases likely to be changed during peer review.
Our approach used GPT-3 to process each paragraph of the text, but it lacked a contextual thread between queries, which mainly affected the Results and Methods sections.
Using chatbots that retain context, such as OpenAI's ChatGPT, could enable the revision of individual paragraphs while considering previously processed text.
Once an official API becomes available for ChatGPT, we plan to update our workflow to support this strategy.
Other open models, such as BLOOM, GLM, or Meta's OPT, could also be used, though they lack the highly usable OpenAI API.
Despite these limitations, we found that models captured the main ideas and generated a revision that often communicated the intended meaning more clearly and concisely.
It is important to note, however, that our assessment of performance in case studies was necessarily subjective, as there could be writing styles that are not widely shared across researchers.


The use of AI-assisted tools for scientific authoring is controversial.
Questions arise concerning the originality and ownership of texts generated by these models.
For example, the International Conference on Machine Learning (ICML) has prohibited the submission of papers that include text generated from a large-scale language model (LLM) [@url:https://icml.cc/Conferences/2023/llm-policy], although editing tools for grammar and spelling correction are allowed.
Our work focuses on revising existing text written by a human author, similar to other tools such as Grammarly [@url:https://www.grammarly.com].
Despite the concerns, there are also significant opportunities.
Our work provides a foundation for a future in which human and machine contributions construct academic manuscripts.
Scientific articles need to adhere to a certain style, which can be time-consuming and require a lot of effort to think about how to communicate a result or finding that has already been obtained.
As machines become increasingly capable of improving scholarly text, humans can focus more on what to communicate to others, rather than on how to write it.
This could lead to a more equitable and productive future for research, where scientists are only limited by their ideas and ability to conduct experiments to uncover the underlying organizing principles of ourselves and our environment.
